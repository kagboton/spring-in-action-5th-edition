Spring in action 5th edition 
----------------------------

1. Fondationnal Spring 

@SpringBootApplication is a composite application that combine three other annotations
- @SpringBootConfiguration: designates the class as a configuration class
- @EnableAutoConfiguration: enables Spring Boot automatic configuration
- @ComponentScan: enables component scanning. This lets declare other classes
with annotations like @Component, @Controler, @Service, and others, to have Spring automatically
discover them and register them as components in the Spring application context.

==>

@RunWith(SpringRunner.class)
@RunWith is a JUnit annotation, providing a test runnner that guides JUnit in running 
a test.
SpringRunner is the runner that provides for the creation of a Spring application context
that the test run against.
SpringRunner is an alias for SpringJUnit4ClassRunner, and was introduced in Spring 4.3 to 
remove the assocaition with a specific version of JUnit

@SpringBootTest telles JUnit to boostrap the test with  Spring Boot capabilities

@WebMvcTest arranges for the test to run in the context of Spring MVC application. It sets up Spring support for testing Spring MVC.
@WebMvcTest(HomeController.class) : arranges for HomeController to be registered in Spring MVC

==>

Spring Boot DevTools
- automatic application restart when code changes
- automatic browser refresh when browser-resources changes
- automatic disable of template caching
- built un H2 console if H2 database is in use


2. Developing web applications : Spring MVC

run spring boot application : mvn spring-boot:run

Spring MVC is annotation-based used to develop web front end for a Spring application


@Data : Lombok annotation that generates all missing methods of a class
@RequiredArgsConstructor
@Slf4j : Lombok-provided annotation that, at runtime will automatically generates an SL4J Logger in the class
    private static finale org.slf4j.Logger log =
        org.slf4j.LoggerFactory.getLogger(DesignTacoController.class);

Thymeleaf's @{} operator is used to produce a context-relative path to the static artifacts
that they're referencing

Field Validation 
Spring MVC supports validation through the Java Bean Validation API or JSR-303 and the implementation of the Validation API such as Hibernate Validator
Validation API and the Hibernate implementation of the Validation API are automatically added to the project as transcient dependencies of Spring Boot starters

Spring Boot starters :: are the dependency descriptors.
 - Spring Boot starters can help to reduce the number of manually added dependencies just by adding one dependency. 

@WebConfig implements the WebMvcConfigurer interface
WebMvcConfigurer :: interface defines severals methods for configuring Spring MVC. It provides default implementation of all the methods.
We just need to override the methods needed
Example to declare a view controller, we override the addViewControllers() method: 
 @Override
    public void addViewControllers(ViewControllerRegistry registry) {
        registry.addViewController("/").setViewName("home");
    }
registry.addViewController("/) returns a ViewControllerRegistration object on which I can call setViewName() to specific the "home "view that the request for "/" should be forward to. 

Template options supported but Spring Boot EnableAutoConfiguration
- Freemarker: spring-boot-starter-freemarker
- Groovy Templates: spring-boot-starter-groovy-templates
- JavaServer Pages (JSP): none (provided by Tomcat or Jetty)
- Mustache: spring-boot-starter-mustache
- Thymeleaf: spring-boot-starter-thymleaf 

Spring detects autom the template used so we can start writting templates in /src/main/resources/templates
If we choose JSP, we should look at somewhere under /WEB-INF. JSP is only an option if we are building our application as a WAR field 
and deploying it in a traditiona servlet container. So if we are building our application as a JAR file, there's no way to satisfy that requirement.

Caching Templates: properties to enable/disable template caching. By default all are true. If we are using Spring Boot's DevTools, they will be disabled
- Freemaker: spring.freemarker.cache
- Groovy Templates: spring.groovy.templatee.cache
- Mustache: spring.mustache.cache
- Thymeleaf: spring.thymeleaf.cache 


3. Working with data

When it come to working relational data, the most common choice are JDBC and th JPA
JDBC: Java Database Connectivity

Spring supports both of these with abstractions. 

3.1. JDBC

JDBC support is rooted in the JdbcTemplate class. It makes queries easier than normal JDBC use.
We need to add JDBC to the project classpath to use JdbcTemplate : spring-boot-starter-jdbc. We can use H2 for the database during development. 

@Repository annotation is added to the class that will handle queries. 
This annotation is one of a handful of stereotype annotations that Spring defines, including @Controller and @Component

- query(): jdbc method that returns a collection of an object. It accepts the SQL for the query as well as an implementationof Spring's RowMapper for mapping each row in the result set of an object
- queryForObject(): works like query() but returns only a single object
- update(): inserting a row. writes or updates in the database. require a String containing the query

Database schema definition: if there's a file named schema.sql in the root of the application's classpath, then the SQL in the fie will be excecuted against the database
Spring Boot will also execute a file named data.sql from the root of the classpath when the application starts 
The files should be placed in the src/main/resources

update() method can accepts a PrepareStatementCreator and a KeyHolder
- PrepareStatementCreator: example
    PreparedStatementCreator psc =
                    new PreparedStatementCreatorFactory(
                            "insert into Taco (name, createAt) values (?, ?)", Types.VARCHAR, Types.TIMESTAMP
                    ).newPreparedStatementCreator(
                            Arrays.asList(
                                    taco.getName(),
                                    new Timestamp(taco.getCreateAt().getTime())
                            )
                    );
- KeyHolder: provides a generated ID


- @SessionAttributes("order") : The class-lvel @SessionAttributes annotation specifies any model objects like the order attribute that should be kept 
in session and available across multiple requests

- @ModelAttribute(name="taco"): ensure that an (Taco) object will be created in the model

- SimpleJdbcInsert: has a couple of usefu methods for executing the insert : execute() amd executeAndReturnKey(). Both methods accept a Map<Spring, Object>, where
the map keys correspond to the column names in the table the data is inserted into

    @Autowired
        public JdbcOrderRepository(JdbcTemplate jdbc) {

            this.orderInserter = new SimpleJdbcInsert(jdbc)
                    .withTableName("Taco_Order")
                    .usingGeneratedKeyColumns("id");

            this.orderTacoInserter = new SimpleJdbcInsert(jdbc)
                    .withTableName("Taco_Order_Tacos");

            this.objectMapper = new ObjectMapper();
        }

- ObjectMapper or Jackson ObjectMapper: java class to serialize Java objects into JSON and deserialize JSON string into Java objects.

- @SuppressWarnings("unchecked"): This annotation allows us to say which kinds of warnings to ignore. To disable compilation warnings
  While warning types can vary by compiler vendor, the two most common are deprecation and unchecked.
      - deprecation: to suppress warnings relative to deprecated method or type
      - unchecked: to suppress warnings relative to unchecked operations. Tells the compiler to ignore when we're using raw types

- org.springframework.web.bind.support.SessionStatus: Simple interface that can be injected into handler methods, allowing them to signal that their session processing is complete. 
- @SessionAttributes: Annotation that indicates the session attributes that a specific handler uses.



3.2. JPA

A few of the most popular Spring Data projects include these:
- Spring Data JPA - JPA persistence against a relational database
- Spring Data MongoDB
- Spring Data Neo4J
- Spring Data Redis
- Spring Data Cassandra


Spring Data JPA starter dependency

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-jpa</artifactId>
</dependency>

This starter dependency brings Spring Data JPA with the Hibernate as the JPA dependency. EclipsLink is another implementation of JPA library.

JPA requires that the entities have a no arguments constructor. We can use @NoArgsConstructor from Lombok. As we dont have to use it, it should be private.
We should then set access attribute to AccessLevel.PRIVATE. In the case that we have final properties that must me set, we should set force attribute to true
Lombok @RequiredArgsConstructor ensures that we'll have a required arguments constructor

With JPA repositories version, the repositories need to extends the org.springframework.data.repository.CrudRepository interface.
The first parameter ot CrudRepository interface is the type of the entity to persist, the second parameter is the type of the entity ID.
EX: public TacoRepository extends CrudRepository<Taco, Long> {}
We dont need any implementation. Spring Data JPA automatically generates an implementation on the fly when the application starts.

However we can customise the JPA repositories

Repository methods are composed of a verb, an optional subject, the word By, and a predicate. 
- findByDeliveryZip (Spring deliveryZip): find(verb)-(no subject)By-DeliveryZip(predicate)
- readOrderByDeliveryZipAndPlacedAtBetween(String deliveryZip, Date startDate, Data endDate): read == find == get

Spring Data method signature include a lot of operators. 

We can also use @Query to perform any query we want. 
Ex: 
@Query("Order o where o.deliveryCity='Seattle'")
List<Order> readOrderDeliveredInSeattle()

We can place OrderBy at the end of the method name to sort the results by a specified column: findByDeliveryCityOrderByDeliveryTO(String city)



4. Spring Security

To enable Spring Boot Security, we have to add the Security starter dependency
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>

With this in place, we have only few security features for our application (no specific role or authorities, no login page, only one user, the username is "user")
To properly secured our application, we need at least to configure Spring security to :
- have a login page, 
- provide multiple users and enable a registration page
- apply different security rules for different request paths.

Configuring Spring Security

@Configuration
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
}

Spring Security offers different options for Configuring a user store : 
- An in-memory user store : good for testing purpose of for a very simple applications
- A JDBC-based user store
- An LDAP-backed user store
- A custom user details Service

We can configure the user store by overriding a "configure()" method defined in the WebSecurityConfigurerAdapter

@Override
protected void configure(AuthenticationManagerBuilder auth) throws Exception {
       
}

AuthenticationManagerBuilder employes a builder-style API to configure authentication details

1. Authentication 
2. Authorization

In-memory user store
auth
    .inMemoryAuthentication()
      .withUser("buzz")
        .password("{noop}infinity")
        .authorities("ROLE_USER");

JDBC-based user store 

auth
    .jdbcAuthentication()
      .dataSource(dataSource)
      .usersByUsernameQuery(
          "select username, password, enabled from Users " +
          "where username=?")
      .authoritiesByUsernameQuery(
          "select username, authority from UserAuthorities " +
          "where username=?")
      .passwordEncoder(new StandardPasswordEncoder("53cr3t");

To encode password, we have to use the passwordEncoder() method. It accepts any implementation of Spring Security's 
PasswordEncoder interface.
Here some implementations:
- BCryptPasswordEncoder: applies bcrypt strong hashing encryption
- NoOpPasswordEncoder: applies no encoding (DEPRECATED)
- Pbkdf2PasswordEncoder: applies PBKDF2 encryption
- SCryptPasswordEncoder: application scrypt hashing encryption
- StandardPasswordEncoder: applies SHA-256 hashing encryption (DEPRECATED) 

We can also create our own implementation of PasswordEncoder if those dont meet our needs.

public interface PasswordEncoder {
  String encode(CharSequence rawPassword);
  boolean matches(CharSequence rawPassword, String encodedPassword);
}

We have to note that the password inside the datebase is never decoded. The user password is encoded, using the samen algorithme and compared
to the value inside the database. The comparaison is performed by the methode Encoder's "matches()" method.

LDAP-backed user store

.userSearchFilter("(uid={0})")
.groupSearchFilter("member={0}")
.userSearchBase("ou=people") // specify that users be searched for where the organizational unit is people
.groupSearchBase"ou=groups") // specify that groups be searched for where the organizational unit is groups
.passwordCompare()
.passwordEncoder(new BCryptPasswordEncoder())
.passwordAttribute("passcode")
.contextSource() // returns a ContextSourceBuilder
        .url("ldap://tacocloud.com:389/dc=tacocloud,dc=com");
        or
.contextSource()
        .root("dc=tacocloud,dc=com") // to use the Spring Security embeded server
        .ldif("classpath:users.ldif"); // specify whith LDIF file to get

- userSearchFilter() and groupSearchFilter() are used to provide filters for the base LDAP queries, which are used to search users and groups

By defaut the search will be done from the root of the LDAP hierarchy, that why the users and groups are empty

- userSearchBase() and groupSearchBase() methodes provide a base for query for finding user and finding groups. 

By default strategy for authenticationg against LDAP is to perform a bind operation

- passwordCompare() - if we want to do password comparison instead of bind operation. 
- passwordAttribute("passcode"); -  to specify the password attribute name if the password is in a different attribute
- contextSource() - to specify the LDAP server location if the server is not on localhost listening on the port 33389 (by default)

When LDAP starts it will attempt to load data from any LDIF (LDAP Data Interchange Format) files that it can find in the classpath

In addition of those user store, we need to create and configure a custom user details service.

Summary
------- 
Step 1: enable spring security by adding the spring security starter dependency
Step 2: configure Spring Security by creating the Security config class and overriding configure() method with the appropriate user store
Step 3: customizing user authentication by creating the user class and repository. The user class implements the UserDetails Spring Security class
Step 4: create and implement a user details service
Step 5: add the userdetails service to the configure method on Spring Security config class. 
        auth.userDetailsService(userDetailsService)
Step 6: add a user registration controller, the registration view (the form), the RegistrationFrom class that have the same field as 
        User class and a method that returns a User with encored password

Step 7: securing web requests. Allow user to access registration page. To do so, we have to implement the configure(HttpSecurity http) method. 
        We shoud configure, the custom login page, logout page, cross-sit request forgery protection.

        protected void configure(HttpSecurity http) throws Exception {
                http
                .authorizeRequests() // returns and object ExpressionInterceptUrlRegistry
                .antMatchers("/design", "/orders")
                .hasRole("ROLE_USER")
                .antMatchers("/", "/**").permitAll()
                .and()
                .formLogin()
                .loginPage("/login)
                .loginProcessingUrl("/authenticate") // to customize the login path
                .usernameParameter("user") // to customize username
                .passwordParameter("pwd") // to customize password
                .defaultSuccessUrl("/design") // to customize default successful url
                .and()
                .logout() // set up a security filter that interceps POST requests to /logout
                .logoutSuccessUrl("/") // custom post-logout landing page
        }
        
        The order of these rules is important. 
        - security rules declared first. If we swap the permitAll rule to come first,  the rule for /design and /orders would have no effect

Configuration methods to define how a path is to be secured: 

- access(String)	Allows access if the given SpEL expression evaluates to true
- anonymous()	Allows access to anonymous users
- authenticated()	Allows access to authenticated users
- denyAll()	Denies access unconditionally
- fullyAuthenticated()	Allows access if the user is fully authenticated (not remembered)
- hasAnyAuthority(String...)	Allows access if the user has any of the given authorities
- hasAnyRole(String...)	Allows access if the user has any of the given roles
- hasAuthority(String)	Allows access if the user has the given authority
- hasIpAddress(String)	Allows access if the request comes from the given IP address
- hasRole(String)	Allows access if the user has the given role
- not()	Negates the effect of any of the other access methods
- permitAll()	Allows access unconditionally
- rememberMe()	Allows access for users who are authenticated via remember-me

Spring Security extensions to the Spring Expression Language:

- authentication	The user’s authentication object
- denyAll	Always evaluates to false
- hasAnyRole(list of roles)	true if the user has any of the given roles
- hasRole(role)	true if the user has the given role
- hasIpAddress(IP address)	true if the request comes from the given IP address
- isAnonymous()	true if the user is anonymous
- isAuthenticated()	true if the user is authenticated
- isFullyAuthenticated()	true if the user is fully authenticated (not authenticated with remember-me)
- isRememberMe()	true if the user was authenticated via remember-me
- permitAll	Always evaluates to true
- principal	The user’s principal object


The login page 
        By default, Spring Security listens for login request at /login and expects that the username and password fields be named username and password.
        By default successful login will take the user to the page that they were navigating to when Spring Security determine that they need to log in
        If the user were directly navigating to /login, a successful login would take them to the root path

Loggin out 
    Were click on logout, the users session will be cleared, and they will be logout of the application .
    By default, they'll be redirected to the login page where they can log in again 


Cross-Site Request Forgery
        A common security attack
        Utilise un faux formulaire qui soumet automatique les informations du client vers une application qui permettra aux hackeurs de prendre la main

        A CSRF token is generated to by the applications to protect again such attacks in a hidden field
        When the form is submitted, the token is sent back to the server along with the rest of the data
        The request is intercepted byt the server and compared with the token that was originally generated.

        <input type="hidden" name="_csrf" th:value="${_csrf.token}"/>

        We dont need to manually add this hidden field if we are useing Spring MVC's JSP or thymeleaf with Spring Security dialect

        With Thymeleaf, we have to make sure that one of the attributes of the <form> element is prefixed as a Thymeleaf attribute
        <form method="POST" th:action="@{/login}" id="loginForm">

        To disable CSRF :
                .and()
                    .csrf()
                    .disable()

Obtain information about the logged-in user
        There a several ways to determine who the user is
        - inject a Principal object into the controller
        - inject an Authentication object inot the controller method
        - use SecurityContextHolder to get at the security context
        - use an @AuthenticationPrincipal annoted method

============== Principal
        @PostMapping
        public String processOrder(@Valid Order order, Errors errors,
                SessionStatus sessionStatus,
                Principal principal) {

        User user = userRepository.findByUsername(
                principal.getName());
        order.setUser(user);

        }
============== Authentication
        @PostMapping
        public String processOrder(@Valid Order order, Errors errors,
                SessionStatus sessionStatus,
                Authentication authentication) {

        ...

        User user = (User) authentication.getPrincipal();
        order.setUser(user);

        ...

        }
=============== @AuthenticationPrincipal
        @PostMapping
        public String processOrder(@Valid Order order, Errors errors,
                SessionStatus sessionStatus,
                @AuthenticationPrincipal User user) {

        }

=============== SecurityContextHolder.getContext returns SecurityContext object
        Authentication authentication =
        SecurityContextHolder.getContext().getAuthentication();
        User user = (User) authentication.getPrincipal()





5. Working with configuration properties

Autoconfiguraton simplifies Spring Application development.
Configuration properties are properties on beans in the Spring application context that can be set from one of several property sources
including JVM system properties, command-line arguments, and environment variables.

How to employ configuration properties to fine-tune what Spring Boot automatically configures ?

2 different kinds of configurations in Spring
- bean wiring: config that declares application components to be created as beans in the Spring application context and how they sould be injected into each other 
- property injection: config that sets values on bean in the Spring application context

These 2 types of configuration are declared explicitly in the same place in XML and java-based configuration.
In java configuration, the @Bean-annoted method instantiate a bean and also set values to its properties.
Ex:
        @Bean
        public DataSource dataSource() {
        return new EmbeddedDataSourceBuilder()
        .setType(H2)
        .addScript("taco_schema.sql")
        .addScripts("user_data.sql", "ingredient_data.sql")
        .build();
        }
Spring boot configuration make this unnecessary. If the Datasource dependency is present in the run-time classpath, Spring Boot
creates an appropriate bean in the Spring application context. 
If we need more specific config, its where configuration properties come in.


Where configuration properties come from ?

The Spring environment pulls from several property sources: 
- JVM system properties, 
- command-line arguments,
- environment variables, 
- application property configuration files

The Spring environment aggregates those properties into a single source and make them available to beans in the application context.
The beans that are automatically configured by Spring Boot are all configurable by properties drawn from the Spring environment.

src/main/resources/application.properties or application.yml is the file where we can set application properties
EX: make the servlet container to listen for requests on some port
server:
  port: 9090

we can also use command line to specify the port 
$ java -jar tacocloud.jar --server.port=9090

we can also set environment variables
$ export SERVER_PORT = 9090



Configuring a data source

spring:
  datasource:
    url: jdbc:mysql://localhost/tacocloud
    username: tacodb
    password: tacopassword
    driver-class-name: com.mysql.jdbc.Driver

We dont need to specify the driver class name, Spring can figure it out from the structure of the database url
The DataSource bean will be pooled using Tomcat’s JDBC connection pool if it’s available on the classpath. 
If not, Spring Boot looks for and uses one of these other connection pool implementations on the classpath:
- HikariCP
- Commons DBCP 2

These are the only connection pool options available through autoconfiguration,

This is the way to specify the database initialization scripts to run when the application starts. 
spring:
  datasource:
    schema:
    - order-schema.sql
    - ingredient-schema.sql
    - taco-schema.sql
    - user-schema.sql
    data:
    - ingredients.sql

Configuring the embedded server

The server will start on a randomly chosen available port
server:
  port: 0

One of the most common things you’ll need to do with the underlying container is to set it up to handle HTTPS requests.
To do that, the first thing you must do is create a keystore using the JDK’s "keytool" command-line utility:

$ keytool -keystore mykeys.jks -genkey -alias tomcat -keyalg RSA

We must follow the instruction and after that set a few properties to enable HTTPS in the embedded server.

server:
  port: 8443
  ssl:
    key-store: file://path/to/mykeys.jks
    key-store-password: letmein
    key-password: letmein

The port 8443 is a common choice for development HTTPS.
Here we are loading the key-store from the filesystem. If we package the server within the application JAR file, we should use a "classpath:" 

Configuring logging

By defaut, Spring Boot configures logging via Logback (http://logback.qos.ch) to write to the console at the INFO level/
logback.xml at the root of the classpath () for full control over the logging Configuration

The most common changes you’ll make to a logging configuration are to change the logging levels and perhaps to specify a file where 
the logs should be written. 
With Spring Both configure properties we can make all those changes without having to create logback.xml file 

Ex: set the root logging level to WARN, but log Spring Security logs at a DEBUG level, 
write the log entries to the file TacoCloud.log at /var/logs/. We ahev to make sure the application has write permission to /var/logs/. 
The log files rotate once they reach 10MB in serialize

logging:
  path: /var/logs/
  file: TacoCloud.log
  level:
    root: WARN
    org:
      springframework:
        security: DEBUG


Using special property values
To use set a property to echo the value of another property, we could use the ${} placeholder.
Ex: use the value of spring.application.name property to set another property called greeting.welcome
greeting:
  welcome: ${spring.application.name}


Creating your own configuration properties
Configuration properties are nothing more than properties of beans that have been designated to accept configureations from Spring's environment abstraction.
To support property injection of configuration properties, Spring Boot provides the @ConfigurationProperties annotation. 
When placed on any Spring bean, it specifies that the properties of that bean can be injected from properties in the Spring environment.

Ex: we have this method inside a controller

@GetMapping
    public String ordersForUser(@AuthenticationPrincipal User user, Model model){ // get an user orders
        Pageable pageable = (Pageable) PageRequest.of(0, 20);
        model.addAttribute("orders", orderRepository.findByUserOrderByPlacedAtDesc(user, pageable));
        return "orderList";
}

Pageable is Spring Data’s way of selecting some subset of the results by a page number and page size. 
In our example the pageable request the fist page (page 0) with a page size of 20 to get up to 20 of the most recently placed orders for the user
Rader than hardcode the size, we can set it with a custom configuration property. 
To do that we have to add the new property in the controller and annotat it with @ConfigurationProperties like this. 


@Controller
...
...
@ConfigurationProperties(prefix = "taco.orders")
public class OrderController {

    private int pageSize;

    public void setPageSize(int pageSize) {
        this.pageSize = pageSize;
    }


    ...

    @GetMapping
    public String ordersForUser(@AuthenticationPrincipal User user, Model model){ // get an user orders
        Pageable pageable = (Pageable) PageRequest.of(0, pageSize);
        model.addAttribute("orders", orderRepository.findByUserOrderByPlacedAtDesc(user, pageable));
        return "orderList";
    }

}

We can now use taco.orders.pageSize in application.properties/application.yml file

taco:
  orders:
    pageSize: 10

 or as an environment variable :  $ export TACO_ORDERS_PAGESIZE=10



@ConfigurationProperties are in fact often placed on beans whose sole purpose in the application is to be holders of configuration data.
This keeps configuration-specific details out of the controllers and other application classes.
It also makes it easy to share common configuration properties among several beans that may make use of that information.


Declaring configuration property metadata
Depending on your IDE, you may have noticed that the taco.orders.pageSize entry in application.yml (or application.properties) has a warning saying something like Unknown Property ‘taco’.
This warning appears because there’s missing metadata concerning the configuration property you just created.
Configuration property metadata is completely optional and doesn’t prevent configuration properties from working. 
But the metadata can be useful for providing some minimal documentation around the configuration properties, especially in the IDE.

To create metadata for our custom configuration properties, we’ll need to create a file under the META-INF (for example, 
in the project under src/main/resources/META-INF) named additional-spring-configuration-metadata.json.

Ex:

{
  "properties": [
    {
      "name": "taco.orders.page-size",
      "type": "java.lang.String",
      "description":
      "Sets the maximum number of orders to display in a list."
    }
  ]
}

Spring Boot’s flexible property naming allows for variations in property names such that taco.orders.page-size is equivalent to taco.orders.pageSize.

Now we need to configure different properties for different development environment


Configuring with profiles

When applications are deployed to different run-time environments, usually some configuration details differ. 
One way to configure properties uniquely in one environment over another is to use environment variables to specify configuration properties instead of defining them in application.properties and application.yml.

For instance, during development you can lean on the autoconfigured embedded H2 database. But in production you can set database configuration properties as environment variables like this:
% export SPRING_DATASOURCE_URL=jdbc:mysql://localhost/tacocloud
% export SPRING_DATASOURCE_USERNAME=tacouser
% export SPRING_DATASOURCE_PASSWORD=tacopassword

This is a way to do but its not the good way. We will use instead Spring profiles.
Profiles are a type of conditional configuration where different beans, configuration classes, and configuration properties are applied or ignored based on what profiles are active at runtime.


One way to define profile-specific properties is to create yet another YAML or properties file containing only the properties for production. 
The name of the file should follow this convention: application-{profile name}.yml or application-{profile name}.properties

Another way to specify profile-specific properties works only with YAML configuration. It involves placing profile-specific properties
 alongside non-profiled properties in application.yml, separated by three hyphens and the spring.profiles property to name the profile. 

Ex: before the hyphens : properties common to all profiles or default. after the hyphens: properties to production profile
logging:
  level:
    tacos: DEBUG

---
spring:
  profiles: prod

  datasource:
    url: jdbc:mysql://localhost/tacocloud
    username: tacouser
    password: tacopassword

logging:
  level:
    tacos: WARN

Activating profiles

Setting profile-specific properties will do no good unless those profiles are active.   
All it takes to make a profile active is to include it in the list of profile names given to the spring.profiles.active property.
Ex: 
spring:
  profiles:
    active:
    - prod

But that’s perhaps the worst possible way to set an active profile. If we set the active profile in application.yml, then that profile becomes the default profile,
and we achieve none of the benefits of using profiles to separate the production-specific properties from development properties. 
Instead, the recommended way to set the active profile(s) is with environment variables. 

Ex: % export SPRING_PROFILES_ACTIVE=prod 
Any applications deployed to that machine will have the prod profile active and the corresponding configuration properties would take precedence over the properties in the default profile.

We can also  set the active profile with a command-line argument like this: % java -jar taco-cloud.jar --spring.profiles.active=prod

We can  specify more than one active profile: % export SPRING_PROFILES_ACTIVE=prod,audit,ha
In Yaml : 
spring:
  profiles:
    active:
    - prod
    - audit
    - ha

Cloud Foundry
If we deploy a Spring application to Cloud Foundry, a profile named cloud is automatically activated for you. 
If Cloud Foundry is our production environment, we'll want to be sure to specify production-specific properties under the cloud profile.


Conditionally creating beans with profiles
Sometimes it’s useful to provide a unique set of beans for different profiles.
The @Profile annotation can designate beans as only being applicable to a given profile.

Ex: the CommandLineRunner created if either the dev profile or qa profile is active. 
@Bean
@Profile("dev", "qa")
public CommandLineRunner dataLoader(IngredientRepository repo,
      UserRepository userRepo, PasswordEncoder encoder) {

  ...

}

Another ex : CommandLineRunner bean were always created unless the prod profile is active. Here, the exclamation mark (!) negates the profile name.
@Bean
@Profile("!prod")
public CommandLineRunner dataLoader(IngredientRepository repo,
      UserRepository userRepo, PasswordEncoder encoder) {

  ...

}

It’s also possible to use @Profile on an entire @Configuration-annotated class.


2. Integrated Spring

We are going to learn how to integrate our Spring application with other applications

Creating REST services
We are going to use what we've learned about Spring MVC to creat RESTful endpoints with Spring MCV controllers
We are going to use a single-page application to render information instead of server-rendered pages we created. 
This application will communicate with the REST API we are going to create to fetch and save taco data.
In a single-page application (SPA), the presentation is decoupled from the backend processing.
It also open the opportunity to integrate with other applications that can consume the API.

The SPA code will communicate with an API by way of HTTP requests.

@GetMapping	HTTP GET requests	Reading resource data
@PostMapping	HTTP POST requests	Creating a resource
@PutMapping	HTTP PUT requests	Updating a resource
@PatchMapping	HTTP PATCH requests	Updating a resource
@DeleteMapping	HTTP DELETE requests	Deleting a resource
@RequestMapping	General purpose request handling; HTTP method specified in the method attribute	 




@RestController(path="/desing", produces="application/json")
@CrossOrigin(origins="*")
DesignTacoController{
        ....
        @GetMapping("/recent")
        public Iterable<Taco> recentTacos() {
        PageRequest page = PageRequest.of(
            0, 12, Sort.by("createdAt").descending());
        return tacoRepo.findAll(page).getContent();
        }
        ...
}

PageRequest is an object to perform paging.
To be able to use this object in a Spring Data repository method, this repository have to extends PagingAndSortingRepository instead of CrudRepository 

@RestController annotation
The @RestController annotation serves two purposes.
First, it’s a stereotype annotation like @Controller and @Service that marks a class for discovery by component scanning.
But most relevant to the discussion of REST, the @RestController annotation tells Spring that all handler methods in the controller
should have their return value written directly to the body of the response, rather than being carried in the model to a view for rendering.
We can alternatively use @Controller like any Spring MVC controller but we'll need to annotate all of the handler methods with @ResponseBody to have the same result
Another option would be to return a ResponseEntity object

@CrossOrigin(origins="*") : this annotation includes CORS(Cors-Origin Resource Sharing) headers in the server responses. 
Our Single-page application will be running on a separate host and/or from the API, the web browser will prevent the application from consuming the API. 
This restriction will be overcome by the annotation.

ResponseEntity<Taco> :
If the object is found we wrap it in a ResponseEntity with an HTTP status of OK like this : return new ResponseEntity<>(optionalTaco.get(), HttpStatus.OK);
If the object is not found, we wrap null in a ResponseEntity with an HTTP status of NOT_FOUND like this :return new ResponseEntity<>(null, HttpStatus.NOT_FOUND);


Sending data to the server

@PostMapping(consumes = "application/json")
@ResponseStatus(HttpStatus.CREATED)
public Taco postTaco(@RequestBody Taco taco){
   return tacoRepository.save(taco);
}
- consumes attribute is to request input what produces is to request output. Here consumes says that the method will only handle requests whonse Content-types mathces application/json.
- @RequestBody indicates that the body of the request should bec converted to a Taco object and bound to the parameter.


Updating data on the server

- PUT : perfom a wholesale replacement opteration rather than an update operation
- PATCH : perform a patch or a partial update of the resource data

For a patch, we should put in our patch method code, what field requires to be updated instead of completely replacing the whole object we are updating (thats what PUT do).
This approach allows the client to only send the properties that should be changed and enables the server to retain existing data for any properties not specified byt hte client
The patch request handler would have to be written to handle patch instructions instead of the domain data.

@PatchMapping(path="/{orderId}", consumes="application/json")
public Order patchOrder(@PathVariable("orderId") Long orderId,
                        @RequestBody Order patch) {

  Order order = repo.findById(orderId).get();
  if (patch.getDeliveryName() != null) {
    order.setDeliveryName(patch.getDeliveryName());
  }
  ...
  // patch logic

  return repo.save(order);
}


Deleting data from the server

@DeleteMapping("/{orderId}")
@ResponseStatus(code=HttpStatus.NO_CONTENT)
public void deleteOrder(@PathVariable("orderId") Long orderId) {
  try {
    repo.deleteById(orderId);
  } catch (EmptyResultDataAccessException e) {}
}

Enabling hypermedia

HATEOAS : Hypermedia as the Engine of Application State is a means of creating self-describing APIs wherein resources returned from an API contain links to related resources

This enables clients to navigate an API with minimal understanding of the API’s URLs. Instead, it understands relationships between the resources served by the API 
and uses its understanding of those relationships to discover the API’s URLs as it traverses those relationships.

A list of taco resource with no hyperlinks
[
  {
    "id": 4,
    "name": "Veg-Out",
    "createdAt": "2018-01-31T20:15:53.219+0000",
    "ingredients": [
      {"id": "FLTO", "name": "Flour Tortilla", "type": "WRAP"},
      {"id": "COTO", "name": "Corn Tortilla", "type": "WRAP"},
      {"id": "TMTO", "name": "Diced Tomatoes", "type": "VEGGIES"},
      {"id": "LETC", "name": "Lettuce", "type": "VEGGIES"},
      {"id": "SLSA", "name": "Salsa", "type": "SAUCE"}
    ]
  },
  ...
]

VS

Without hypermedia, the client doesn’t know the operation to HTTP perform.
If the API is enabled with hypermedia, the API will describe its own URLs, relieving the client of needing to be hardcoded with that knowledge.

A list of taco resource that includes hyperlinks

{
  "_embedded": {
    "tacoResourceList": [
      {
        "name": "Veg-Out",
        "createdAt": "2018-01-31T20:15:53.219+0000",
        "ingredients": [
          {
            "name": "Flour Tortilla", "type": "WRAP",
            "_links": {
              "self": { "href": "http://localhost:8080/ingredients/FLTO" }
            }
          },
          {
            "name": "Corn Tortilla", "type": "WRAP",
            "_links": {
              "self": { "href": "http://localhost:8080/ingredients/COTO" }
            }
          },
          {
            "name": "Diced Tomatoes", "type": "VEGGIES",
            "_links": {
              "self": { "href": "http://localhost:8080/ingredients/TMTO" }
            }
          },
          {
            "name": "Lettuce", "type": "VEGGIES",
            "_links": {
              "self": { "href": "http://localhost:8080/ingredients/LETC" }
            }
          },
          {
            "name": "Salsa", "type": "SAUCE",
            "_links": {
              "self": { "href": "http://localhost:8080/ingredients/SLSA" }
            }
          }
        ],
        "_links": {
          "self": { "href": "http://localhost:8080/design/4" }
        }
      },

      ...
    ]
  },
  "_links": {
    "recents": {
      "href": "http://localhost:8080/design/recent"
    }
  }
}

This particular flavor of HATEOAS is known as HAL (Hypertext Application Language; http://stateless.co/hal_specification.html),
a simple and commonly used format for embedding hyperlinks in JSON responses.

The Spring HATEOAS project brings hyperlink support to Spring. It offers a set of classes and resource assemblers that can be used to add links
 to resources before returning them from a Spring MVC controller.

To enable hypermedia in the Taco Cloud API, you’ll need to add the Spring HATEOAS starter dependency to the build:

<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-hateoas</artifactId>
</dependency>

This starter not only adds Spring HATEOAS to the project’s classpath, but also provides for autoconfiguration to enable Spring HATEOAS. 


Adding hyperlinks

Spring HATEOAS provides two primary types that represent hyperlinked resources:
- Resource : reprensents a single resource
- Resources : is a collection of resources
They are capable of carrying links to other resources. When returned from a Spring MVC REST controller method, they links they carry will be includedin the JSON (or XML)
received by the client.

Ex:
@GetMapping("/recent")
public Resources<Resource<Taco>> recentTacos() {
  PageRequest page = PageRequest.of(
          0, 12, Sort.by("createdAt").descending());

  List<Taco> tacos = tacoRepo.findAll(page).getContent();
  Resources<Resource<Taco>> recentResources = Resources.wrap(tacos);

  recentResources.add(
      new Link("http://localhost:8080/design/recent", "recents"));
  return recentResources;
}

ControllerLinkBuilder : 
This link builder know what the hostname is without we having to hardcode it. 
And it provides a handy fluent API to help us build links relative to the base URL of any controller.

ControllerLinkBuilder uses the controller’s base path as the foundation of the Link object we’re creating.

Resources<Resource<Taco>> recentResources = Resources.wrap(tacos);
recentResources.add(
  ControllerLinkBuilder.linkTo(DesignTacoController.class)
                       .slash("recent")
                       .withRel("recents"));

slash(): literally appends a slash (/) and the given value to the URL
withRel(): is to specifiy the name of the relation

We can also build the link without using the slash() method like this : 

Resources<Resource<Taco>> recentResources = Resources.wrap(tacos);
recentResources.add(
        linkTo(methodOn(DesignTacoController.class).recentTacos())
        .withRel("recents"));

methodOn(): another ControllerLinkBuilder method, it takes the controller class and lets you make a call to the recentTacos() method,
which is intercepted by ControllerLinkBuilder and used to determine not only the controller’s base path, but also the path mapped to recentTacos()

Creating resource assemblers

We need to add links to the taco resource contained within the list of taco
Here we are going to create a TacoResource class. This class isnt that different from the Taco domain but extends ResourceSupport to 
inherit a list of Link object and methods to manage the list of links. 
The TacoResource resource class has a constructor thay accepts a Taco and copies the pertinent properties from the Taco to its own properties (leaving out the id property). 
It makes it easy to convert a single Taco object to a TacoResource. 

package io.kagboton.tacoscloud.utils;

import io.kagboton.tacoscloud.domain.Ingredient;
import io.kagboton.tacoscloud.domain.Taco;
import lombok.Getter;
import org.springframework.hateoas.ResourceSupport;

import java.util.Date;
import java.util.List;

public class TacoResource extends ResourceSupport {

    @Getter
    private final String name;
    @Getter
    private final Date createdAt;
    @Getter
    private  final List<Ingredient> ingredients;

    public TacoResource(Taco taco) {
        this.name = taco.getName();
        this.createdAt = taco.getCreatedAt();
        this.ingredients = taco.getIngredients();
    }
}


We also need to create a resource assembler

package io.kagboton.tacoscloud.utils;

import io.kagboton.tacoscloud.controller.DesignTacoController;
import io.kagboton.tacoscloud.domain.Taco;
import org.springframework.hateoas.mvc.ResourceAssemblerSupport;

public class TacoResourceAssembler extends ResourceAssemblerSupport<Taco, TacoResource> {

    public TacoResourceAssembler() {
        super(DesignTacoController.class, TacoResource.class);
    }

    @Override
    protected TacoResource instantiateResource(Taco taco) {
        return new TacoResource(taco);
    }

     @Override
    public TacoResource toResource(Taco taco) {
        return createResourceWithId(taco.getId(), taco);
    }
}

TacoResourceAssembler has a default constructor that informs the superclass (ResourceAssemblerSupport) that it will be using DesignTacoController to determine the base path 
for any URLs in links it creates when creating TacoResource

The instantiateResource() method is overridden to instantiate a TacoResource given a Taco. This method would be optional if TacoResource had a default constructor.
In this case, however, TacoResource requires construction with a Taco, so you’re required to override it.

Finally, the toResource() method is the only method that’s strictly mandatory when extending ResourceAssemblerSupport. 
Here you’re telling it to create a TacoResource object from a Taco,  and to automatically give it a self link with the URL being derived from the Taco object’s id property.

toResource() appears to have a similar purpose to instantiateResource(), but they serve slightly different purposes. 
instantiateResource() is intended to only instantiate a Resource object, toResource() is intended not only to create the Resource object, but also to populate it with links. Under the covers, toResource() will call instantiateResource().


@GetMapping("/recent")
    public Resources<TacoResource> getRecentTacos(){
        PageRequest page = PageRequest.of(0, 12, Sort.by("createdAt").descending()); // page request object

        List<Taco> tacos = tacoRepository.findAll(page).getContent(); // get the recent tacos list

        List<TacoResource> tacoResources = new TacoResourceAssembler().toResources(tacos); // convert our Taco objects list to TacoResource objects list using TacoResourceAssembler

        Resources<TacoResource> recentResources =  new Resources<TacoResource>(tacoResources);

        recentResources.add(
                ControllerLinkBuilder.linkTo(methodOn(DesignTacoController.class).getRecentTacos())
                    .withRel("recents") // dynamically populate our Resources<TacoResource> with the recents links 
        );

        return recentResources; // return resources of tacoResources to take advantage of our new TacoResource type  
    }


Rather than return a Resources<Resource<Taco>>, recentTacos() now returns a Resources<TacoResource> to take advantage of our new TacoResource type. 
At this point, a GET request to /design/recent will produce a list of tacos, each with a self link and a recents link on the list itself. 
But the ingredients will still be without a link. To address that, we'll create a new resource and resource assembler for ingredients.
We also need to change TacoResource so that it carries IngredientResource instead of Ingredient objects. We are going to perform this change by using IngredientResourceAssembler toResource() method.

Our recent tacos list is now completely outfitted with hyperlinks, not only for itself (the recents link), but also for all of its taco entries and the ingredients of those tacos.


Naming embedded relationships

By annotating TacoResource with @Relation, you can specify how Spring HATEOAS should name the field in the resulting JSON

@Relation(value="taco", collectionRelation="tacos")
public class TacoResource extends ResourceSupport {
  ...
}

Enabling data-backed services

Spring Data REST is another member of the Spring Data family that automatically creates REST APIs for repositories created by Spring Data.
By doing little more than adding Spring Data REST to our build, we get an API with operations for each repository interface we’ve defined.

To start using Spring Data REST, we add the following dependency to our build:
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-data-rest</artifactId>
</dependency>

By doing nothing more than adding this dependency to our build, we’re not only getting an endpoint for Spring Data repositories (ingredients, tacos, orders, users), 
but the resources that come back also contain hyperlinks!
We should know that every endpoint and option that Spring Data REST create support POST, PUT, and DELETE methods.

One thing we might want to do is set a base path for the API so that its endpoints are distinct and don’t collide with any controllers we write.
To adjust the base path for the API, set the spring.data.rest.base-path property:
Ex:
spring:
  data:
    rest:
      base-path: /api

This sets the base path for Spring Data REST endpoints to /api

Adjusting resource paths and relation names
Sometimes, such as with “taco”, Spring Data REST trips up on a word and the pluralized version isn’t quite right. 
EX: Spring Data REST pluralized “taco” as “tacoes”

Spring Data REST also exposes a home resource that has links for all exposed endpoints : $ curl localhost:8080/api

The @RestResource annotation lets us give the entity any relation name and path we want.
Ex:
   @Data
   @Entity
   @RestResource(rel="tacos", path="tacos")
   public class Taco {
   ...
   }


Paging and sorting

 "http://localhost:9090/api/tacoes{?page,size,sort}"

 This link offers optional page, size, and sort parameters.
 By default, requests to a collection resource such as /api/tacos will return up to 20 items per page from the first page.
 We can adjust the page size and the page displayed by specifying the page and size parameters in our request.

 $ curl "localhost:8080/api/tacos?size=5" :: request the first page of tacos where the page size is 5
 $ curl "localhost:8080/api/tacos?size=5&page=1" :: request the second page of tacos where the page size is 5

 Notice that the page parameter is zero-based, which means that asking for page 1 is actually asking for the second page. 

 The sort parameter lets you sort the resulting list by any property of the entity

 $ curl "localhost:8080/api/tacos?sort=createdAt,desc&page=0&size=12" :: fetch the 12 most recently created tacos, 
 the sort parameter specifies that we should sort by the createdDate property and that it should be sorted in descending order 


Adding custom endpoints

Spring Data REST is great at creating endpoints for performing CRUD operations against Spring Data repositories. 
But sometimes we need to break away from the default CRUD API and create an endpoint that gets to the core of the problem.

When we write our own API controllers, their endpoints seem somewhat detached from the Spring Data REST endpoints in a couple of ways:

- Our own controller endpoints aren’t mapped under Spring Data REST’s base path. We could force their mappings to be prefixed with whatever base path we want, 
  including the Spring Data REST base path, but if the base path were to change, we’d need to edit the controller’s mappings to match.
- Any endpoints we define in our own controllers won’t be automatically included as hyperlinks in the resources returned by Spring Data REST endpoints. 
  This means that clients won’t be able to discover our custom endpoints with a relation name.

To resolve that problem Spring Data REST includes @RepositoryRestController

@RepositoryRestController : all mappings in a @RepositoryRestController-annotated controller will have their path prefixed with the value 
of the spring.data.rest.base-path property (which we’ve configured as /api)

One important thing to notice is that although @RepositoryRestController is named similarly to @RestController, it doesn’t carry the same semantics as @RestController.
Specifically, it doesn’t ensure that values returned from handler methods are automatically written to the body of the response. 
Therefore we need to either annotate the method with @ResponseBody or return a ResponseEntity that wraps the response data. 
We should then return a ResponseEntity.

With RecentTacosController in play, requests for /api/tacos/recent will return up to 15 of the most recently created tacos, 
without the need for paging and sorting parameters in the URL. 
But it still doesn’t appear in the hyperlinks list when requesting /api/tacos. Let’s fix that.

Adding custom hyperlinks to Spring Data endpoints
By declaring a resource processor bean, however, we can add links to the list of links that Spring Data REST automatically includes.
Spring Data HATEOAS offers ResourceProcessor, an interface for manipulating resources before they’re returned through the API.
For our purposes, we need an implementation of ResourceProcessor that adds a recents link to any resource of type PagedResources<Resource <Taco>> 
(the type returned for the /api/tacos endpoint). The next listing shows a bean declaration method that defines such a ResourceProcessor.

@Bean
public ResourceProcessor<PagedResources<Resource<Taco>>>
  tacoProcessor(EntityLinks links) {

  return new ResourceProcessor<PagedResources<Resource<Taco>>>() {
    @Override
    public PagedResources<Resource<Taco>> process(
                        PagedResources<Resource<Taco>> resource) {
      resource.add(
          links.linkFor(Taco.class)
               .slash("recent")
               .withRel("recents"));
      return resource;
    }
  };
}

The ResourceProcessor is defined as an anonymous inner class and declared as a bean to be created in the Spring application context.
Spring HATEOAS will discover this bean (as well as any other beans of type ResourceProcessor) automatically and will apply them to the appropriate resources.
In this case, if a PagedResources<Resource<Taco>> is returned from a controller, it will receive a link for the most recently created tacos. 
This includes the response for requests for /api/tacos.


Summary :

J'ai apris que l'annotation @RestController permt de creer une API qui renvoi des informations dans son body. L'annotation @Controller peu le faire mais les 
methodes implementee au sein du controleur doivent revoyer une response entity pour simuler le meme fonctionnement que @RestController.

J'ai apris essanetiellement que pour que le client d'une API puisse automatiquement detecter et utiliser les liens disponible au sein d'une API, il faut utiliser les 
hyperliens. 
Les hypermedia sont geres par Spring HATEOAS. Au lieu de retourner une simple list d'objets, ou une response entity, on renvoie une liste de ressource a laquelle on 
injecte les hyperliens generes automatiquement par les methodes (linkFor, methodOn, slash, etc.) de la classe ControllerLinkBuilder.

J'ai egalement appris que Spring Data REST permet de generer une API de toutes les repositories gerees au sein du projet. En ajoutant simplement la dependance maven
du starter Spring Data REST, on otbtien une API a laquelle on peu appliquer toute les methodes HTTP connues (POST, GET, PUT, PATCH, DELETE).



Consuming REST Services


Sending messages asynchronously

- Asynchronous messaging
- Sending messages with JMS, RabbitMQ, and Kafka
- Pulling messages from a broker
- Listening to messages

Asynchronous messages is a way to indirectly sending messages from one application to another without waiting for a response.
This indirection affords looser coupling and greater scalability between the communicating applications.
Message-driven POJOs: a way to receive messages that resembles EJB's message-driven beans (MDBs).

Sending messages with JMS
JMS : Java Message Service. JMS is a Java standard that defines a common API for working with message brokers.
With JMS, all compliant (brokers) implementations can be worked with via a common interface in much the same way that JDBC has given relational database operations a
common interface

Spring supports JMS through a template-based abstraction known as JmsTemplate.
Spring also supports the notion of message-driven POJOs: simple Java objects that react to messages arriving on a queue or topic in an asynchronous fashion.


Setting up JMS

Before we can use JMS, we must add a JMS client to our project’s build. 
We must decide whether we’re going to use Apache ActiveMQ, or the newer Apache ActiveMQ Artemis broker.

ActiveMQ dependency:
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-activemq</artifactId>
</dependency>

ActiveMQ Artemis dependency:
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-artemis</artifactId>
</dependency>


Artemis is a next-generation reimplementation of ActiveMQ, effectively making ActiveMQ a legacy option. We are going to use Artemis here.
By default, Spring assumes that your Artemis broker is listening on localhost at port 61616.
That’s fine for development purposes, but once we’re ready to send our application into production, we’ll need to set a few properties that tell Spring 
how to access the broker.

Property and their Description
==============================
spring.artemis.host:	The broker’s host
spring.artemis.port: 	The broker’s port
spring.artemis.user: 	The user to use to access the broker (optional)
spring.artemis.password: 	The password to use to access the broker (optional)

For example, consider the following entry from an application.yml file that might be used in a non-development setting

spring:
  artemis:
    host: artemis.tacocloud.com
    port: 61617
    user: tacoweb
    password: l3tm31n


If we were to use ActiveMQ instead of Artemis, we’d need to use the ActiveMQ-specific properties

Property and their Description
==============================
spring.activemq.broker-url:	The URL of the broker
spring.activemq.user:	The user to use to access the broker (optional)
spring.activemq.password:	The password to use to access the broker (optional)
spring.activemq.in-memory:	Whether or not to start an in-memory broker (default: true)

Notice that instead of offering separate properties for the broker’s hostname and port, an ActiveMQ broker’s address is specified with a single property
spring:
  activemq:
    broker-url: tcp://activemq.tacocloud.com
    user: tacoweb
    password: l3tm31n

If we’re using ActiveMQ, we will, however, need to set the spring.activemq.in-memory property to false to prevent Spring from starting an in-memory broker.
An in-memory broker may seem useful, but it’s only helpful when we’ll be consuming messages from the same application that publishes them.

Instead of using an embedded broker, we’ll want to install and start an Artemis (or ActiveMQ) broker before moving on.
- Artemis— https://activemq.apache.org/artemis/docs/latest/using-server.html
- ActiveMQ— http://activemq.apache.org/getting-started.html#GettingStarted-Pre-InstallationRequirements

Sending messages with JMSTemplate
JmsTemplate is the centerpiece of Spring’s JMS integration support.
Much like Spring’s other template-oriented components, JmsTemplate eliminates a lot of boilerplate code that would otherwise be required to work with JMS

JmsTemplate has several methods that are useful for sending messages, including the following:

// Send raw messages
void send(MessageCreator messageCreator) throws JmsException;
void send(Destination destination, MessageCreator messageCreator) throws JmsException;
void send(String destinationName, MessageCreator messageCreator) throws JmsException;

// Send messages converted from objects
void convertAndSend(Object message) throws JmsException;
void convertAndSend(Destination destination, Object message) throws JmsException;
void convertAndSend(String destinationName, Object message)throws JmsException;

// Send messages converted from objects with post-processing
void convertAndSend(Object message, MessagePostProcessor postProcessor) throws JmsException;
void convertAndSend(Destination destination, Object message, MessagePostProcessor postProcessor) throws JmsException;
void convertAndSend(String destinationName, Object message, MessagePostProcessor postProcessor) throws JmsException;

As we can seee there are really only two methods, send() and convertAndSend(), each overridden to support different parameters.

methods require a MessageCreator to manufacture a Message object.
convertAndSend() methods accept an Object and automatically convert that Object into a Message behind the scenes

- MessageCreator
- Destination
- MessagePostProcessor : allow for customization of the Message before it's sent

Sending an order with .send() to a default destination
======================================================
package tacos.messaging;
import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.Session;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.core.MessageCreator;
import org.springframework.stereotype.Service;

@Service
public class JmsOrderMessagingService implements OrderMessagingService {
  private JmsTemplate jms;

  @Autowired
  public JmsOrderMessagingService(JmsTemplate jms) {
    this.jms = jms;
  }

  @Override
  public void sendOrder(Order order) {
    jms.send(new MessageCreator() {
                @Override
                public Message createMessage(Session session)
                                              throws JMSException {
                  return session.createObjectMessage(order);
                }
              }
    );
  }

  // or with lambda
  @Override
  public void sendOrder(Order order){
      jmsTemplate.send( session -> session.createObjectMessage(order));
  }

}

But notice that the call to jms.send() doesn’t specify a destination. 
In order for this to work, we must also specify a default destination name with the spring.jms.template.default-destination property. 

spring:
  jms:
    template:
      default-destination: tacocloud.order.queue

In many cases, using a default destination is the easiest choice. 
It lets us specify the destination name once, allowing the code to only be concerned with sending messages, without regard for where they’re being sent. 

If we want to specify a destination, the easiest way is to declare a Destination bean and then inject it into the bean that performs messaging. 
For example, the following bean declares the Taco Cloud order queue Destination:

@Bean
public Destination orderQueue() {
  return new ActiveMQQueue("tacocloud.order.queue");
}

But in practice, we’ll almost never specify anything more than the destination name. It’s often easier to just send the name as the first parameter to send():

@Override
public void sendOrder(Order order) {
  jms.send(
      "tacocloud.order.queue",
      session -> session.createObjectMessage(order));
} 


convertAndSend() :: Converting messages before sending

JmsTemplates’s convertAndSend() method simplifies message publication by eliminating the need to provide a MessageCreator.
Instead, we pass the object that’s to be sent directly to convertAndSend(), and the object will be converted into a Message before being sent.

For example, the following reimplementation of sendOrder() uses convertAndSend() to send an Order to a named destination:

@Override
public void sendOrder(Order order) {
  jms.convertAndSend("tacocloud.order.queue", order);
}

The Order passed into convertAndSend() is converted into a Message before it’s sent.

Behind the scenes, here is how the converstion is performed.
MessageConverter is a Spring-defined interface that has only two methods to be implemented:

public interface MessageConverter {
  Message toMessage(Object object, Session session)throws JMSException, MessageConversionException;
  Object fromMessage(Message message)
}

Although this interface is simple enough to implement, we often won’t need to create a custom implementation. 
Spring already offers a handful of implementations, such as those described:


Message converter and What it does
==================================
MappingJackson2MessageConverter: 	Uses the Jackson 2 JSON library to convert messages to and from JSON
MarshallingMessageConverter: 	Uses JAXB to convert messages to and from XML
MessagingMessageConverter:	Converts a Message from the messaging abstraction to and from a Message using an underlying MessageConverter for the payload and a JmsHeaderMapper to map the JMS headers to and from standard message headers
SimpleMessageConverter:	Converts Strings to and from TextMessage, byte arrays to and from BytesMessage, Maps to and from MapMessage, and Serializable objects to and from ObjectMessage

SimpleMessageConverter is the default, but it requires that the object being sent implement Serializable. 
This may be a good idea, but we may prefer to use one of the other message converters, such as MappingJackson2MessageConverter, to avoid that restriction.



To apply a different message converter, all we must do is declare an instance of the chosen converter as a bean. 
For example, the following bean declaration will enable MappingJackson2MessageConverter to be used instead of SimpleMessageConverter:

@Bean
public MappingJackson2MessageConverter messageConverter() {
  MappingJackson2MessageConverter messageConverter =
                          new MappingJackson2MessageConverter();
  messageConverter.setTypeIdPropertyName("_typeId");
  return messageConverter;
}

Notice that we called setTypeIdPropertyName() on the MappingJackson2MessageConverter before returning it.
This is very important, as it enables the receiver to know what type to convert an incoming message to.
By default, it will contain the fully qualified classname of the type being converted. 
But that’s somewhat inflexible, requiring that the receiver also have the same type, with the same fully qualified classname.

To allow for more flexibility, we can map a synthetic type name to the actual type by calling setTypeIdMappings() on the message converter.
For example, the following change to the message converter bean method maps a synthetic order type ID to the Order class:

@Bean
public MappingJackson2MessageConverter messageConverter() {
  MappingJackson2MessageConverter messageConverter =
                          new MappingJackson2MessageConverter();
  messageConverter.setTypeIdPropertyName("_typeId");

  Map<String, Class<?>> typeIdMappings = new HashMap<String, Class<?>>();
  typeIdMappings.put("order", Order.class);
  messageConverter.setTypeIdMappings(typeIdMappings);

  return messageConverter;
}


Instead of the fully qualified classname being sent in the message’s _typeId property, the value 'order' will be sent.
At the receiving application, a similar message converter will have been configured, mapping 'order' to its own understanding of what an order is. 
That implementation of an order may be in a different package, have a different name, and even have a subset of the sender’s Order properties.

Poat-processing messages

Here we want to keep the information about the source of a message. For the Order example, we would like to know weither the order is placed online (WEB) or in the stores (STORE).
A solution would be to add a custom header to the message to carry the order's source. 

With send() method it will be like this:
========================================
jms.send("tacocloud.order.queue",
    session -> {
        Message message = session.createObjectMessage(order);
        message.setStringProperty("X_ORDER_SOURCE", "WEB");
    });

We a re using the Message object and call the setStringProperty() to set this information to the message 

With convertAndSend() it cant be done like that as the Message object is created behind the scenes.

We can perform this by passing in a MessagePostProcessor as the final parameter to convertAndSend():
=======================================================================
jms.convertAndSend("tacocloud.order.queue", order, new MessagePostProcessor() {
  @Override
  public Message postProcessMessage(Message message) throws JMSException {
    message.setStringProperty("X_ORDER_SOURCE", "WEB");
    return message;
  }
});

As a functionnal interface, MessagePostProcessor can be replace the annonymous inner class with a lambda:
jms.convertAndSend("tacocloud.order.queue", order,
    message -> {
      message.setStringProperty("X_ORDER_SOURCE", "WEB");
      return message;
    }
);

We may find ourself using the same MessagePostProcessor for several different calls to convertAndSend().
In those cases, perhaps a method reference is a better choice than a lambda, avoiding unnecessary code duplication:

@GetMapping("/convertAndSend/order")
public String convertAndSendOrder() {
  Order order = buildOrder();
  jms.convertAndSend("tacocloud.order.queue", order,
      this::addOrderSource);
  return "Convert and sent order";
}

private Message addOrderSource(Message message) throws JMSException {
  message.setStringProperty("X_ORDER_SOURCE", "WEB");
  return message;
}

Receiving JMS messages

We have 2 choices : 
- a pull model: our code requests a message ans waits untils one arrives
- a push model: messages are handed to our code as they become available

JmsTemplate offers several methods for receiving messages, but all of them use a pull model.

Message receive() throws JmsException;
Message receive(Destination destination) throws JmsException;
Message receive(String destinationName) throws JmsException;

Object receiveAndConvert() throws JmsException;
Object receiveAndConvert(Destination destination) throws JmsException;
Object receiveAndConvert(String destinationName) throws JmsException;

The receive() methods receive a raw Message, whereas the receiveAndConvert() methods use a configured message converter to convert messages into domain types. 

Here some code that pulls an Order from the tacocloud.order.queue destination.

package tacos.kitchen.messaging.jms;
import javax.jms.Message;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.support.converter.MessageConverter;
import org.springframework.stereotype.Component;

@Component
public class JmsOrderReceiver implements OrderReceiver {
  private JmsTemplate jms;
  private MessageConverter converter;

  @Autowired
  public JmsOrderReceiver(JmsTemplate jms, MessageConverter converter) {
    this.jms = jms;
    this.converter = converter;
  }

  public Order receiveOrder() {
    Message message = jms.receive("tacocloud.order.queue");
    return (Order) converter.fromMessage(message);
  }
}